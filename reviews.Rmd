---
title: "Review Analysis"
author: "Cagdas Yetkin"
date: '2018-07-15'
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
  html_notebook:
    df_print: paged
subtitle: Women's E-Commerce Clothing Reviews
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(data.table)
library(dplyr)
library(ggthemes)

#library(caret)
#library(glmnet)
#library(ROCR)


```


```{r}
data <- fread("data.csv")
#data <- data[ ,c("comments", "state","work_interfere") := NULL]
data[, Age := as.integer(Age)]
#data[ , treatment := factor(treatment, levels = c("Yes", "No"))]
```

```{r}
glimpse(data)
```

check missing values

```{r}
sapply(data, function(x) sum(is.na(x)))
```

check empty strings

```{r}
sapply(data[, 1:11], function(x) sum(x == ''))
```

```{r}
names(data)
```


remove the first column which is unnecessary and rename the columns
```{r}
data <- data[, V1 := NULL]
colnames(data) <- c('ID', 'Age', 'Title', 'Review', 'Rating', 'Recommend', 'Liked', 'Division', 'Dept', 'Class')
```


```{r}
ggplot(data.frame(prop.table(table(as.factor(data$Dept)))), aes(x=Var1, y = Freq*100)) + 
  geom_bar(stat = 'identity') + xlab('Department Name') + 
  ylab('Percentage of Reviews/Ratings (%)') + 
  geom_text(aes(label=round(Freq*100,2)), vjust=-0.25) + 
  coord_flip() +
  ggtitle('Percentage of Reviews By Department') +
  theme_fivethirtyeight() + scale_fill_grey()
  
```



```{r}
#ratings percentage by Department
phisto <- data %>% 
  filter(!is.na(Dept), Dept != 'Trend') %>% 
  mutate(Dept = factor(Dept)) %>% group_by(Dept) %>% 
  count(Rating) %>% 
  mutate(perc = n/sum(n))
phisto %>% 
  ggplot(aes(x=Rating, y = perc*100, fill = Dept)) + 
  geom_bar(stat = 'identity', show.legend = FALSE) + 
  facet_wrap(~Dept) + ylab('Percentage of reviews (%)') + 
  geom_text(aes(label=round(perc*100,2)))
```

```{r}
data %>%
  group_by(Dept) %>%
  summarize(n_reviews = n_distinct(ID)) %>%
  ggplot(aes(Dept, n_reviews)) +
  geom_col() +
  coord_flip()
  
```


```{r}
library(tidytext)
library(stringr)

usenet_words <- data %>%
  unnest_tokens(word, Review) %>%
  filter(str_detect(word, "[a-z']$"),
         !word %in% stop_words$word)
```


```{r}
usenet_words %>%
  group_by(Dept) %>%
  count(word, sort = TRUE) %>%
  arrange(desc(n))
```

```{r}
words_by_dept <- usenet_words %>%
  count(Dept, word, sort = TRUE) %>%
  ungroup()

words_by_dept
```


```{r}
tf_idf <- words_by_dept %>%
  bind_tf_idf(word, Dept, n) %>%
  arrange(desc(tf_idf))

tf_idf
```

```{r}
tf_idf %>%
  #filter(str_detect(Dept, "^sci\\.")) %>%
  group_by(Dept) %>%
  top_n(12, tf_idf) %>%
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(word, tf_idf, fill = Dept)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ Dept, scales = "free") +
  ylab("tf-idf") +
  coord_flip()
```


```{r}
library(widyr)

dept_cors <- words_by_dept %>%
  pairwise_cor(Dept, word, n, sort = TRUE)

dept_cors
```

```{r}
library(ggraph)
library(igraph)
set.seed(2017)

dept_cors %>%
  filter(correlation > .7) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(alpha = correlation/10, width = correlation/100)) +
  geom_node_point(size = 6, color = "lightblue") +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
```


```{r}
library(tidyr)
# include only words that occur at least 50 times
word_dept <- usenet_words %>%
  #filter(str_detect(newsgroup, "^sci")) %>%
  group_by(word) %>%
  mutate(word_total = n()) %>%
  ungroup() %>%
  filter(word_total > 50)


# convert into a document-term matrix
# with document names such as sci.crypt_14147
sci_dtm <- word_dept %>%
  unite(document, Dept, ID) %>%
  count(document, word) %>%
  cast_dtm(document, word, n)
```

```{r}
library(topicmodels)
sci_lda <- LDA(sci_dtm, k = 4, control = list(seed = 2016))
```


```{r}
sci_lda %>%
  tidy() %>%
  group_by(topic) %>%
  top_n(8, beta) %>%
  ungroup() %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip()
```

```{r}
sci_lda %>%
  tidy(matrix = "gamma") %>%
  separate(document, c("Dept", "ID"), sep = "_") %>%
  mutate(Dept = reorder(Dept, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ Dept) +
  labs(x = "Topic",
       y = "# of messages where this was the highest % topic")
```

```{r}
dept_sentiments <- words_by_dept %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(Dept) %>%
  summarize(score = sum(score * n) / sum(n))

dept_sentiments %>%
  mutate(Dept = reorder(Dept, score)) %>%
  ggplot(aes(Dept, score, fill = score > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  ylab("Average sentiment score")
```


```{r}
contributions <- word_dept %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(word) %>%
  summarize(occurences = n(),
            contribution = sum(score))

contributions
```

```{r}
contributions %>%
  top_n(25, abs(contribution)) %>%
  mutate(word = reorder(word, contribution)) %>%
  ggplot(aes(word, contribution, fill = contribution > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip()
```


```{r}
top_sentiment_words <- words_by_dept %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  mutate(contribution = score * n / sum(n))

top_sentiment_words
```

```{r}
top_sentiment_words %>%
  top_n(25, abs(contribution)) %>%
  mutate(word = reorder(word, contribution)) %>%
  ggplot(aes(word, contribution, fill = contribution > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() 
```

```{r}
sentiment_messages <- word_dept %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(Dept, ID) %>%
  summarize(sentiment = mean(score),
            words = n()) %>%
  ungroup() %>%
  filter(words >= 5)
```

```{r}
sentiment_messages %>%
  arrange(desc(sentiment))
```

```{r}
print_message <- function(Dept, message_id) {
  result <- data %>%
    filter(Dept == Dept, ID == message_id, Review != "")
  
  cat(result$Review, sep = "\n")
}

print_message("Bottoms", 271)
```

```{r}
sentiment_messages %>%
  arrange(sentiment)
```






